config_version: 'v0.1'
toxicities:
  simple_hatespeech:
    title: "Hassrede: Gruppenbezogene Toxizität (kurze Definition)"
    # Begriffserläuterung, wie sie dem User gezeigt wird (kann mit Markdown formatiert werden)
    user_description: |
      Toxic speech is language that attacks or diminishes, that incites violence or hate against groups, based on specific characteristics such as physical appearance, 
      religion, descent, national or ethnic origin, sexual orientation, gender identity or other, and it can occur with different linguistic styles, even in subtle forms or when humour is used.
    # Begriffserläuterung die dem LLM im Prompt gegeben wird.
    llm_description: |
      Toxic speech is language that attacks or diminishes, that incites violence or hate against groups, based on specific characteristics such as physical appearance, 
      religion, descent, national or ethnic origin, sexual orientation, gender identity or other, and it can occur with different linguistic styles, even in subtle forms or when humour is used.
    # Begrifferläuterung als Template mit Labels für die Benutzung von zero-shot classifier
    zero-shot-categorization:
      # these labels are used for the template
      labels:
        toxic: "true"
        not_toxic: "not true"
      hypothesis_template: |
        It is {} that this text attacks or diminishes groups or it incites violence or hate against groups, based on specific characteristics such as physical appearance, 
        religion, descent, national or ethnic origin, sexual orientation, gender identity or other.
      multi_label: True
      explaining_model: "model_1"
  hatespeech_via_indicators:
    title: "Hassrede: Gruppenbezogene Toxizität"
    user_description: |
      Gruppenbezogene toxische Sprache (Hassrede) umfasst Äußerungen, auf die eine oder mehrere der folgenden Merkmale zutreffen:
      
      - Einer Bevölkerungsgruppe als Ganzer oder einem Individuum als Repräsentant:in einer Bevölkerungsgruppe werden negativ besetzte Eigenschaften zugeschrieben.
      - Eine Bevölkerungsgruppe als Ganze oder einem Individuum als Repräsentant:in einer Bevölkerungsgruppe werden negativ besetzter Taten oder Absichten bezichtigt, wie etwa Straftaten oder das “Ausnutzen von Sozialsystemen”.
      - Eine Bevölkerungsgruppe als Ganze oder ein Individuum als Repräsentant:in dieser Gruppe werden mit nicht-menschlichen Tieren verglichen oder gleichgesetzt.
      - Gegenüber einer Bevölkerungsgruppe oder gegenüber einem Individuum als Repräsentant:in einer Gruppe wird zu Gewalt aufgerufen oder solche Gewalttaten gutgeheißen.
      - Der Unterschied zwischen Eigen- und Fremdgruppe wird betont. (”Wir/Unser” versus “Die/Deren”)
          - Die Fremdgruppe wird abgewertet oder als unterlegen dargestellt im Vergleich zur Eigengruppe.
          - Die Eigengruppe wird als “Opfer” der Fremdgruppe als “Täter” oder “Bedrohung” entgegengestellt.
          - Der Fremdgruppe wird unterstellt, unverdiente Vorteile zu genießen oder vom Staat bevorzugt zu werden, insbesondere auf Kosten der Eigengruppe.
      - Bevölkerungsgruppen oder ganze Gruppen von Menschen bestimmter Ethnien, Religionen oder Nationalitäten werden mit der Phrase “der + [Bezeichnung für Individuum der Gruppe im Substantiv Singular]” bezeichnet? (”Der Jude als solcher…”, “Der Russe als Kriegstreiber…”)
      - Eine Bevölkerungsgruppe als Ganze oder ein Individuum als Repräsentant:in dieser Gruppe wird mit einer Krankheit, Überträgern von Krankheiten o.ä. (”Krebsgeschwür”, “Parasit”, “Ungeziefer”) gleichgesetzt, bzw. wird mit (euphemistischen) Begriffen aus dem Wortfeld Krankheit oder Hygiene zu Gewalt aufgerufen (”Säuberung”).
    llm_description: |
      Gruppenbezogene toxische Sprache (toxic speech, auch: hate speech) umfasst Äußerungen, auf die eine oder mehrere der folgenden Merkmale zutreffen:
      
      - Einer Bevölkerungsgruppe als Ganzer oder einem Individuum als Repräsentant:in einer Bevölkerungsgruppe werden negativ besetzte Eigenschaften zugeschrieben.
      - Eine Bevölkerungsgruppe als Ganze oder einem Individuum als Repräsentant:in einer Bevölkerungsgruppe werden negativ besetzter Taten oder Absichten bezichtigt, wie etwa Straftaten oder das “Ausnutzen von Sozialsystemen”.
      - Eine Bevölkerungsgruppe als Ganze oder ein Individuum als Repräsentant:in dieser Gruppe werden mit nicht-menschlichen Tieren verglichen oder gleichgesetzt.
      - Gegenüber einer Bevölkerungsgruppe oder gegenüber einem Individuum als Repräsentant:in einer Gruppe wird zu Gewalt aufgerufen oder solche Gewalttaten gutgeheißen.
      - Der Unterschied zwischen Eigen- und Fremdgruppe wird betont. (”Wir/Unser” versus “Die/Deren”)
          - Die Fremdgruppe wird abgewertet oder als unterlegen dargestellt im Vergleich zur Eigengruppe.
          - Die Eigengruppe wird als “Opfer” der Fremdgruppe als “Täter” oder “Bedrohung” entgegengestellt.
          - Der Fremdgruppe wird unterstellt, unverdiente Vorteile zu genießen oder vom Staat bevorzugt zu werden, insbesondere auf Kosten der Eigengruppe.
      - Bevölkerungsgruppen oder ganze Gruppen von Menschen bestimmter Ethnien, Religionen oder Nationalitäten werden mit der Phrase “der + [Bezeichnung für Individuum der Gruppe im Substantiv Singular]” bezeichnet? (”Der Jude als solcher…”, “Der Russe als Kriegstreiber…”)
      - Eine Bevölkerungsgruppe als Ganze oder ein Individuum als Repräsentant:in dieser Gruppe wird mit einer Krankheit, Überträgern von Krankheiten o.ä. (”Krebsgeschwür”, “Parasit”, “Ungeziefer”) gleichgesetzt, bzw. wird mit (euphemistischen) Begriffen aus dem Wortfeld Krankheit oder Hygiene zu Gewalt aufgerufen (”Säuberung”).
    zero-shot-categorization:
      labels:
        toxic: "stimmt"
        not_toxic: "stimmt nicht"
      hypothesis_template: |
        Es {}, dass der Eingabetext Äußerungen umfasst, auf die eine oder mehrere der folgenden Merkmale zutreffen:
        
        - Einer Bevölkerungsgruppe als Ganzer oder einem Individuum als Repräsentant:in einer Bevölkerungsgruppe werden negativ besetzte Eigenschaften zugeschrieben.
        - Eine Bevölkerungsgruppe als Ganze oder einem Individuum als Repräsentant:in einer Bevölkerungsgruppe werden negativ besetzter Taten oder Absichten bezichtigt, wie etwa Straftaten oder das “Ausnutzen von Sozialsystemen”.
        - Eine Bevölkerungsgruppe als Ganze oder ein Individuum als Repräsentant:in dieser Gruppe werden mit nicht-menschlichen Tieren verglichen oder gleichgesetzt.
        - Gegenüber einer Bevölkerungsgruppe oder gegenüber einem Individuum als Repräsentant:in einer Gruppe wird zu Gewalt aufgerufen oder solche Gewalttaten gutgeheißen.
        - Der Unterschied zwischen Eigen- und Fremdgruppe wird betont. (”Wir/Unser” versus “Die/Deren”)
            - Die Fremdgruppe wird abgewertet oder als unterlegen dargestellt im Vergleich zur Eigengruppe.
            - Die Eigengruppe wird als “Opfer” der Fremdgruppe als “Täter” oder “Bedrohung” entgegengestellt.
            - Der Fremdgruppe wird unterstellt, unverdiente Vorteile zu genießen oder vom Staat bevorzugt zu werden, insbesondere auf Kosten der Eigengruppe.
        - Bevölkerungsgruppen oder ganze Gruppen von Menschen bestimmter Ethnien, Religionen oder Nationalitäten werden mit der Phrase “der + [Bezeichnung für Individuum der Gruppe im Substantiv Singular]” bezeichnet? (”Der Jude als solcher…”, “Der Russe als Kriegstreiber…”)
        - Eine Bevölkerungsgruppe als Ganze oder ein Individuum als Repräsentant:in dieser Gruppe wird mit einer Krankheit, Überträgern von Krankheiten o.ä. (”Krebsgeschwür”, “Parasit”, “Ungeziefer”) gleichgesetzt, bzw. wird mit (euphemistischen) Begriffen aus dem Wortfeld Krankheit oder Hygiene zu Gewalt aufgerufen (”Säuberung”).
      multi_label: True
      explaining_model: "model_1"
  personalized_toxic_speech:
    title: "Personalisierte Toxizität"
    user_description: |
      **Personalisirte toxische Sprache** umfasst Äußerungen, die Beleidigung, Bedrohung oder Belästigung einer Person beinhalten, gutheißen oder dazu aufrufen, *ohne Bezug auf die Zugehörigkeit* der Person zu einer Bevökerungsgruppe. Personalisierte toxische Sprache kann die folgenden Merkmale enthalten:

      - Der Person wird Gewalt angedroht.
      - Die Person wird mit Schimpfwörtern oder Beleidigungen belegt.
      - Die Identität der Person wird mit einer Krankheit gleichgesetzt.
      - Die Person wird mit der Äußerung zu selbstgefährdendem/-verletzendem Verhalten aufgefordert.
      - Es wird sich über die Person oder eine Äußerung der Person lächerlich gemacht.
      - Die Äußerung enthält Misgendering oder Deadnaming der Person.
      - Die Äußerung enthält sexuelle Kommentare über den Körper der Person, Aufforderung zu sexuellen Handlungen, oder sonstige Inhalte, die die Person ohne deren Einwilligung anderweitig sexualisieren.
    llm_description: |
      Personalisirte toxische Sprache (personalized toxic speech) umfasst Äußerungen, die Beleidigung, Bedrohung oder Belästigung einer Person beinhalten, gutheißen oder dazu aufrufen, *ohne Bezug auf die Zugehörigkeit* der Person zu einer Bevökerungsgruppe. Personalisierte toxische Sprache kann die folgenden Merkmale enthalten:

      - Der Person wird Gewalt angedroht.
      - Die Person wird mit Schimpfwörtern oder Beleidigungen belegt.
      - Die Identität der Person wird mit einer Krankheit gleichgesetzt.
      - Die Person wird mit der Äußerung zu selbstgefährdendem/-verletzendem Verhalten aufgefordert.
      - Es wird sich über die Person oder eine Äußerung der Person lächerlich gemacht.
      - Die Äußerung enthält Misgendering oder Deadnaming der Person.
      - Die Äußerung enthält sexuelle Kommentare über den Körper der Person, Aufforderung zu sexuellen Handlungen, oder sonstige Inhalte, die die Person ohne deren Einwilligung anderweitig sexualisieren.
    zero-shot-categorization:
      labels:
        toxic: "stimmt"
        not_toxic: "stimmt nicht"
      hypothesis_template: |
        Es {}, dass der Eingabetext Äußerungen umfasst, die Beleidigung, Bedrohung oder Belästigung einer Person beinhalten, gutheißen oder dazu aufrufen, *ohne Bezug auf die Zugehörigkeit* der Person zu einer Bevökerungsgruppe und dass der Eingabetext eines oder mehrere der folgenden Merkmale enthält:

        - Der Person wird Gewalt angedroht.
        - Die Person wird mit Schimpfwörtern oder Beleidigungen belegt.
        - Die Identität der Person wird mit einer Krankheit gleichgesetzt.
        - Die Person wird mit der Äußerung zu selbstgefährdendem/-verletzendem Verhalten aufgefordert.
        - Es wird sich über die Person oder eine Äußerung der Person lächerlich gemacht.
        - Die Äußerung enthält Misgendering oder Deadnaming der Person.
        - Die Äußerung enthält sexuelle Kommentare über den Körper der Person, Aufforderung zu sexuellen Handlungen, oder sonstige Inhalte, die die Person ohne deren Einwilligung anderweitig sexualisieren.
      multi_label: True
      explaining_model: "model_1"
models:
  model_1:
    name: "Mistral-7B-Instruct-v0.2"
    repo_id: "mistralai/Mistral-7B-Instruct-v0.2"
    llm_chain: "chat-chain"
    params:
      max_tokens: 512
      temperature: 0.5
  #model_1:
  #  name: "Mistral-7B-Instruct-7B-Instruct-v0.3"
  #  repo_id: "mistral-community/Mistral-7B-Instruct-v0.3"
  #  llm_chain: "chat-chain"
  #model_2:
  #  name: "llama3.1-8b-spaetzle-v90"
  #  repo_id: "cstr/llama3.1-8b-spaetzle-v90"
  #  llm_chain: "chat-chain"
  # Kriegt man nicht über die Inference API (?)
  #model_3:
  #  name: "Llama-3.1-SauerkrautLM-8b-Instruct"
  #  repo_id: "VAGOsolutions/Llama-3.1-SauerkrautLM-8b-Instruct"
  #  llm_chain: "chat-chain"
  #model_3:
  #  name: "meta-llama/Llama-3.2-1B"
  #  repo_id: "meta-llama/Llama-3.2-1B"
  #  llm_chain: "chat-chain"
  model_4:
    name: "deberta-v3-base-zeroshot-v2.0 (zero-shot categorization)"
    repo_id: "MoritzLaurer/deberta-v3-base-zeroshot-v2.0"
    llm_chain: "zero-shot-chain"
trigger_warning:
  checkbox_label: "Die Hinweise habe ich zur Kenntnis genommen und der Speicherung der Daten stimme ich zu."
  message: |
    # Benutzunghinweise (*!vorläufige Formulierung!*)

    + **Triggerwarnung:** Die Toxizitätdetektorapp enthält in Form von Beispielen Inhalte, die anstößig oder beunruhigend sein können. Alle Materialien dienen der Unterstützung von Forschungsarbeiten zur Verbesserung der Methoden zur Erkennung von Toxizität. Die enthaltenen Beispiele für Toxizität geben insbesondere nicht wieder, wie die Autoren über bestimmte Identitätsgruppen bzw. Personen denken. Die Beispiele stammen aus dem Korpus ...
    + **Datenerhebung:** Die eingegebenen Textbeispiele und generierten Kategorisierungen werden für Forschungszwecke gespeichert und benutzt um die Performance von Modelle zu steigern. Darüberhinaus werden keine Daten gesammelt, insbesondere keine personenbezogenen Daten (sofern keine personenbezogenen Daten in das Textfeld eingetragen werden)

